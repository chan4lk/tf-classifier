{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 65%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Display entire width of browser\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 65%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImages(pathIn, pathOut):\n",
    "    count = 0\n",
    "    vidcap = cv.VideoCapture(pathIn)\n",
    "    success,image = vidcap.read()\n",
    "    success = True\n",
    "    while success:\n",
    "      vidcap.set(cv.CAP_PROP_POS_MSEC,(count*1000))    # added this line \n",
    "      success,image = vidcap.read()\n",
    "      print('Read a new frame: ', success)     \n",
    "      cv.imwrite( pathOut + \"/frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "      count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 96\n",
    "h = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir(path):\n",
    "    fileNames = []\n",
    "    for root, dirs, files in os.walk(path):  \n",
    "        for filename in files: \n",
    "            fileNames.append(filename)            \n",
    "    return fileNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list_dir('../videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video-1.mp4\n"
     ]
    }
   ],
   "source": [
    "print(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(videoRoot, imageRoot):\n",
    "    videos = list_dir(videoRoot)\n",
    "    for video in videos:\n",
    "        videoPath = videoRoot + '/' + video\n",
    "        videoName = video.split('.')[0]\n",
    "        imagePath = imageRoot+'/' +videoName\n",
    "        if not os.path.exists(imagePath):\n",
    "            os.makedirs(imagePath)\n",
    "            extractImages(videoPath,imagePath)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract('../videos', '../images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [00:00, 263641.97it/s]\n"
     ]
    }
   ],
   "source": [
    "labelsFile = '../labels/labels.csv'\n",
    "def read_labels(lablesFile):\n",
    "    labelData = []\n",
    "    with open(lablesFile) as inf:\n",
    "        for line in tqdm(inf):            \n",
    "            video, frame, label, clazz = line.strip().split(\",\")\n",
    "            frame = int(frame)\n",
    "            label = int(label)\n",
    "            labelData.append({'video':video, 'frame':frame, 'label':label, 'class':clazz})\n",
    "    return labelData\n",
    "\n",
    "labels = read_labels(labelsFile)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file, labels):    \n",
    "    for l in labels:         \n",
    "        if 'frame' + str(l['frame']) + '.jpg' == file:\n",
    "            if l['class'] == 'Light':                \n",
    "                return np.array([1,0])\n",
    "            else:\n",
    "                return np.array([0,1])\n",
    "    return np.array([1,1])\n",
    "    \n",
    "def train_data_with_label(train_data, labels):\n",
    "    train_images = []    \n",
    "    for i in tqdm(os.listdir(train_data)):        \n",
    "        path = os.path.join(train_data, i)        \n",
    "        img = cv.imread(path, cv.IMREAD_GRAYSCALE)\n",
    "        img = cv.resize(img, (w,h))     \n",
    "        label = get_label(i, labels)      \n",
    "        train_images.append([np.array(img),label])              \n",
    "    #shuffle(train_images)\n",
    "    return train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 265/265 [00:04<00:00, 53.65it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data_with_label('../images/video-1', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 95, 140,  98, ..., 120,  83,  68],\n",
       "        [116, 125, 149, ...,  81,  76,  64],\n",
       "        [123, 128, 150, ...,  75,  67,  75],\n",
       "        ...,\n",
       "        [ 87,  84,  88, ...,  42,  40,  43],\n",
       "        [ 90,  92,  96, ...,  42,  40,  40],\n",
       "        [ 94,  97, 104, ...,  42,  40,  40]], dtype=uint8), array([0, 1])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 265/265 [00:02<00:00, 100.84it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = train_data_with_label('../images/video-1', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_img_data = np.array([i[0] for i in train_data]).reshape(-1, w,h,1)\n",
    "tr_lbl_data = np.array([i[1] for i in train_data])\n",
    "\n",
    "tst_img_data = np.array([i[0] for i in test_data]).reshape(-1, w,h,1)\n",
    "tst_lbl_data = np.array([i[1] for i in test_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for i in tr_lbl_data:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "265/265 [==============================] - ETA: 3:25 - loss: 1.2476 - acc: 0.800 - ETA: 1:41 - loss: 0.6238 - acc: 0.900 - ETA: 1:06 - loss: 0.9532 - acc: 0.900 - ETA: 48s - loss: 0.7149 - acc: 0.925 - ETA: 37s - loss: 0.5719 - acc: 0.94 - ETA: 30s - loss: 0.4766 - acc: 0.95 - ETA: 25s - loss: 0.8690 - acc: 0.92 - ETA: 21s - loss: 0.9619 - acc: 0.92 - ETA: 18s - loss: 1.0341 - acc: 0.92 - ETA: 15s - loss: 0.9369 - acc: 0.93 - ETA: 13s - loss: 0.8518 - acc: 0.93 - ETA: 11s - loss: 0.7808 - acc: 0.94 - ETA: 10s - loss: 0.7207 - acc: 0.94 - ETA: 9s - loss: 0.6692 - acc: 0.9500 - ETA: 7s - loss: 0.7321 - acc: 0.946 - ETA: 6s - loss: 0.6863 - acc: 0.950 - ETA: 6s - loss: 0.7408 - acc: 0.947 - ETA: 5s - loss: 0.7892 - acc: 0.944 - ETA: 4s - loss: 1.0021 - acc: 0.931 - ETA: 3s - loss: 1.0326 - acc: 0.930 - ETA: 3s - loss: 0.9834 - acc: 0.933 - ETA: 2s - loss: 1.0120 - acc: 0.931 - ETA: 1s - loss: 1.0381 - acc: 0.930 - ETA: 1s - loss: 0.9948 - acc: 0.933 - ETA: 0s - loss: 0.9550 - acc: 0.936 - ETA: 0s - loss: 0.9183 - acc: 0.938 - 13s 48ms/step - loss: 0.9618 - acc: 0.9358\n",
      "Epoch 2/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 0.6447 - acc: 0.9600    - ETA: 3s - loss: 0.5373 - acc: 0.966 - ETA: 3s - loss: 0.4605 - acc: 0.971 - ETA: 2s - loss: 0.4091 - acc: 0.975 - ETA: 2s - loss: 0.5427 - acc: 0.966 - ETA: 2s - loss: 0.8108 - acc: 0.950 - ETA: 2s - loss: 0.7371 - acc: 0.954 - ETA: 2s - loss: 0.6757 - acc: 0.958 - ETA: 2s - loss: 0.6237 - acc: 0.961 - ETA: 2s - loss: 0.6943 - acc: 0.957 - ETA: 1s - loss: 0.6480 - acc: 0.960 - ETA: 1s - loss: 0.6075 - acc: 0.962 - ETA: 1s - loss: 0.5717 - acc: 0.964 - ETA: 1s - loss: 0.6295 - acc: 0.961 - ETA: 1s - loss: 0.7661 - acc: 0.952 - ETA: 1s - loss: 0.8083 - acc: 0.950 - ETA: 0s - loss: 0.7699 - acc: 0.952 - ETA: 0s - loss: 0.7349 - acc: 0.954 - ETA: 0s - loss: 0.8431 - acc: 0.947 - ETA: 0s - loss: 0.9423 - acc: 0.941 - ETA: 0s - loss: 0.9690 - acc: 0.940 - ETA: 0s - loss: 0.9318 - acc: 0.942 - 4s 16ms/step - loss: 0.9142 - acc: 0.9434\n",
      "Epoch 3/50\n",
      "265/265 [==============================] - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 0.8197 - acc: 0.9500    - ETA: 3s - loss: 1.0838 - acc: 0.933 - ETA: 3s - loss: 0.8128 - acc: 0.950 - ETA: 3s - loss: 0.6503 - acc: 0.960 - ETA: 3s - loss: 0.5419 - acc: 0.966 - ETA: 3s - loss: 0.4645 - acc: 0.971 - ETA: 2s - loss: 0.4064 - acc: 0.975 - ETA: 2s - loss: 0.3613 - acc: 0.977 - ETA: 2s - loss: 0.3251 - acc: 0.980 - ETA: 2s - loss: 0.5886 - acc: 0.963 - ETA: 2s - loss: 0.5396 - acc: 0.966 - ETA: 2s - loss: 0.4981 - acc: 0.969 - ETA: 2s - loss: 0.6927 - acc: 0.957 - ETA: 1s - loss: 0.6466 - acc: 0.960 - ETA: 1s - loss: 0.6062 - acc: 0.962 - ETA: 1s - loss: 0.5705 - acc: 0.964 - ETA: 1s - loss: 0.6284 - acc: 0.961 - ETA: 1s - loss: 0.6801 - acc: 0.957 - ETA: 1s - loss: 0.7267 - acc: 0.955 - ETA: 0s - loss: 0.8456 - acc: 0.947 - ETA: 0s - loss: 0.8804 - acc: 0.945 - ETA: 0s - loss: 0.9122 - acc: 0.943 - ETA: 0s - loss: 0.9414 - acc: 0.941 - ETA: 0s - loss: 0.9682 - acc: 0.940 - ETA: 0s - loss: 0.9310 - acc: 0.942 - 5s 18ms/step - loss: 0.9134 - acc: 0.9434\n",
      "Epoch 4/50\n",
      "265/265 [==============================] - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 0.5428 - acc: 0.9667    - ETA: 4s - loss: 0.4071 - acc: 0.975 - ETA: 4s - loss: 0.9704 - acc: 0.940 - ETA: 3s - loss: 0.8087 - acc: 0.950 - ETA: 3s - loss: 0.6931 - acc: 0.957 - ETA: 3s - loss: 0.6065 - acc: 0.962 - ETA: 3s - loss: 0.7182 - acc: 0.955 - ETA: 3s - loss: 0.8076 - acc: 0.950 - ETA: 3s - loss: 0.7341 - acc: 0.954 - ETA: 2s - loss: 0.8073 - acc: 0.950 - ETA: 2s - loss: 0.7452 - acc: 0.953 - ETA: 2s - loss: 0.8071 - acc: 0.950 - ETA: 2s - loss: 0.7533 - acc: 0.953 - ETA: 2s - loss: 0.9077 - acc: 0.943 - ETA: 1s - loss: 0.9491 - acc: 0.941 - ETA: 1s - loss: 0.8964 - acc: 0.944 - ETA: 1s - loss: 0.9340 - acc: 0.942 - ETA: 1s - loss: 0.8873 - acc: 0.945 - ETA: 1s - loss: 0.9218 - acc: 0.942 - ETA: 0s - loss: 0.9532 - acc: 0.940 - ETA: 0s - loss: 0.9117 - acc: 0.943 - ETA: 0s - loss: 0.8738 - acc: 0.945 - ETA: 0s - loss: 0.9033 - acc: 0.944 - ETA: 0s - loss: 0.9305 - acc: 0.942 - 5s 20ms/step - loss: 0.9130 - acc: 0.9434\n",
      "Epoch 5/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 0.6447 - acc: 0.9600    - ETA: 4s - loss: 0.5373 - acc: 0.966 - ETA: 3s - loss: 0.4605 - acc: 0.971 - ETA: 3s - loss: 0.6044 - acc: 0.962 - ETA: 3s - loss: 0.7164 - acc: 0.955 - ETA: 3s - loss: 0.6447 - acc: 0.960 - ETA: 3s - loss: 0.7326 - acc: 0.954 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.9919 - acc: 0.938 - ETA: 2s - loss: 1.0362 - acc: 0.935 - ETA: 2s - loss: 0.9671 - acc: 0.940 - ETA: 2s - loss: 1.0074 - acc: 0.937 - ETA: 1s - loss: 0.9481 - acc: 0.941 - ETA: 1s - loss: 0.8954 - acc: 0.944 - ETA: 1s - loss: 0.8483 - acc: 0.947 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 1s - loss: 0.7678 - acc: 0.952 - ETA: 0s - loss: 0.8794 - acc: 0.945 - ETA: 0s - loss: 0.8412 - acc: 0.947 - ETA: 0s - loss: 0.8733 - acc: 0.945 - ETA: 0s - loss: 0.9029 - acc: 0.944 - ETA: 0s - loss: 0.9301 - acc: 0.942 - 5s 19ms/step - loss: 0.9126 - acc: 0.9434\n",
      "Epoch 6/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 0.8059 - acc: 0.9500    - ETA: 3s - loss: 0.5373 - acc: 0.966 - ETA: 4s - loss: 0.4030 - acc: 0.975 - ETA: 3s - loss: 0.6447 - acc: 0.960 - ETA: 3s - loss: 0.5373 - acc: 0.966 - ETA: 3s - loss: 0.6908 - acc: 0.957 - ETA: 3s - loss: 0.8062 - acc: 0.950 - ETA: 3s - loss: 0.8957 - acc: 0.944 - ETA: 3s - loss: 1.1285 - acc: 0.930 - ETA: 2s - loss: 1.0259 - acc: 0.936 - ETA: 2s - loss: 1.0747 - acc: 0.933 - ETA: 2s - loss: 0.9921 - acc: 0.938 - ETA: 2s - loss: 0.9212 - acc: 0.942 - ETA: 2s - loss: 0.8598 - acc: 0.946 - ETA: 2s - loss: 0.9068 - acc: 0.943 - ETA: 1s - loss: 0.9483 - acc: 0.941 - ETA: 1s - loss: 0.8956 - acc: 0.944 - ETA: 1s - loss: 1.0181 - acc: 0.936 - ETA: 1s - loss: 0.9672 - acc: 0.940 - ETA: 1s - loss: 0.9211 - acc: 0.942 - ETA: 0s - loss: 0.8793 - acc: 0.945 - ETA: 0s - loss: 0.8410 - acc: 0.947 - ETA: 0s - loss: 1.0075 - acc: 0.937 - ETA: 0s - loss: 0.9672 - acc: 0.940 - ETA: 0s - loss: 0.9300 - acc: 0.942 - 5s 20ms/step - loss: 0.9124 - acc: 0.9434\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 0.5373 - acc: 0.9667    - ETA: 3s - loss: 0.6908 - acc: 0.957 - ETA: 3s - loss: 0.8061 - acc: 0.950 - ETA: 3s - loss: 0.8956 - acc: 0.944 - ETA: 3s - loss: 0.9672 - acc: 0.940 - ETA: 3s - loss: 0.8793 - acc: 0.945 - ETA: 3s - loss: 0.8060 - acc: 0.950 - ETA: 2s - loss: 0.8680 - acc: 0.946 - ETA: 2s - loss: 0.9211 - acc: 0.942 - ETA: 2s - loss: 0.9672 - acc: 0.940 - ETA: 2s - loss: 0.9067 - acc: 0.943 - ETA: 2s - loss: 0.8534 - acc: 0.947 - ETA: 1s - loss: 0.8060 - acc: 0.950 - ETA: 1s - loss: 0.9332 - acc: 0.942 - ETA: 1s - loss: 0.9672 - acc: 0.940 - ETA: 1s - loss: 0.9979 - acc: 0.938 - ETA: 0s - loss: 1.0258 - acc: 0.936 - ETA: 0s - loss: 0.9812 - acc: 0.939 - ETA: 0s - loss: 1.0074 - acc: 0.937 - ETA: 0s - loss: 0.9671 - acc: 0.940 - ETA: 0s - loss: 0.9300 - acc: 0.942 - 6s 21ms/step - loss: 0.9124 - acc: 0.9434\n",
      "Epoch 8/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.6118 - acc: 0.9000    - ETA: 4s - loss: 1.6118 - acc: 0.900 - ETA: 3s - loss: 1.2089 - acc: 0.925 - ETA: 3s - loss: 0.9671 - acc: 0.940 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.6908 - acc: 0.957 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.7164 - acc: 0.955 - ETA: 2s - loss: 0.6447 - acc: 0.960 - ETA: 2s - loss: 0.5861 - acc: 0.963 - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 2s - loss: 0.4959 - acc: 0.969 - ETA: 2s - loss: 0.6908 - acc: 0.957 - ETA: 2s - loss: 0.6447 - acc: 0.960 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 1s - loss: 0.8533 - acc: 0.947 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 1s - loss: 0.8483 - acc: 0.947 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.8443 - acc: 0.947 - ETA: 0s - loss: 0.8792 - acc: 0.945 - ETA: 0s - loss: 0.9110 - acc: 0.943 - ETA: 0s - loss: 0.9402 - acc: 0.941 - ETA: 0s - loss: 0.9026 - acc: 0.944 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 18ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 9/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 2s - loss: 0.2931 - acc: 0.9818    - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 2s - loss: 0.6199 - acc: 0.961 - ETA: 2s - loss: 0.5756 - acc: 0.964 - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 1s - loss: 0.6044 - acc: 0.962 - ETA: 1s - loss: 0.5689 - acc: 0.964 - ETA: 1s - loss: 0.6268 - acc: 0.961 - ETA: 1s - loss: 0.6787 - acc: 0.957 - ETA: 1s - loss: 0.6447 - acc: 0.960 - ETA: 1s - loss: 0.6140 - acc: 0.961 - ETA: 0s - loss: 0.7327 - acc: 0.954 - ETA: 0s - loss: 0.7709 - acc: 0.952 - ETA: 0s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.9026 - acc: 0.944 - ETA: 0s - loss: 0.8679 - acc: 0.946 - 5s 19ms/step - loss: 0.9124 - acc: 0.9434\n",
      "Epoch 10/50\n",
      "265/265 [==============================] - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.0745 - acc: 0.9333    - ETA: 4s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.6447 - acc: 0.960 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.9210 - acc: 0.942 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.8954 - acc: 0.944 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7326 - acc: 0.954 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7439 - acc: 0.953 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7522 - acc: 0.953 - ETA: 1s - loss: 1.0074 - acc: 0.937 - ETA: 1s - loss: 1.0429 - acc: 0.935 - ETA: 1s - loss: 1.0745 - acc: 0.933 - ETA: 1s - loss: 1.0180 - acc: 0.936 - ETA: 1s - loss: 1.0477 - acc: 0.935 - ETA: 1s - loss: 1.0745 - acc: 0.933 - ETA: 0s - loss: 1.0257 - acc: 0.936 - ETA: 0s - loss: 0.9811 - acc: 0.939 - ETA: 0s - loss: 1.0074 - acc: 0.937 - ETA: 0s - loss: 0.9671 - acc: 0.940 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 19ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 11/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 2.3791e-05 - acc: 1.000 - ETA: 4s - loss: 0.8059 - acc: 0.9500    - ETA: 4s - loss: 1.0745 - acc: 0.933 - ETA: 4s - loss: 1.2089 - acc: 0.925 - ETA: 4s - loss: 0.9671 - acc: 0.940 - ETA: 4s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.9210 - acc: 0.942 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 1.2536 - acc: 0.922 - ETA: 3s - loss: 1.1283 - acc: 0.930 - ETA: 3s - loss: 1.0257 - acc: 0.936 - ETA: 2s - loss: 0.9402 - acc: 0.941 - ETA: 2s - loss: 0.8679 - acc: 0.946 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7522 - acc: 0.953 - ETA: 2s - loss: 0.7052 - acc: 0.956 - ETA: 1s - loss: 0.7585 - acc: 0.952 - ETA: 1s - loss: 0.8955 - acc: 0.944 - ETA: 1s - loss: 0.9332 - acc: 0.942 - ETA: 1s - loss: 0.8865 - acc: 0.945 - ETA: 1s - loss: 1.1513 - acc: 0.928 - ETA: 0s - loss: 1.0990 - acc: 0.931 - ETA: 0s - loss: 1.0512 - acc: 0.934 - ETA: 0s - loss: 1.0074 - acc: 0.937 - ETA: 0s - loss: 0.9671 - acc: 0.940 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 19ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 12/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 0.2303 - acc: 0.9857    - ETA: 3s - loss: 0.2015 - acc: 0.987 - ETA: 3s - loss: 0.1791 - acc: 0.988 - ETA: 3s - loss: 0.4835 - acc: 0.970 - ETA: 2s - loss: 0.5861 - acc: 0.963 - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 2s - loss: 0.4959 - acc: 0.969 - ETA: 2s - loss: 0.5757 - acc: 0.964 - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 1s - loss: 0.5037 - acc: 0.968 - ETA: 1s - loss: 0.4741 - acc: 0.970 - ETA: 1s - loss: 0.6268 - acc: 0.961 - ETA: 1s - loss: 0.6787 - acc: 0.957 - ETA: 1s - loss: 0.6447 - acc: 0.960 - ETA: 1s - loss: 0.6908 - acc: 0.957 - ETA: 0s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.7709 - acc: 0.952 - ETA: 0s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.9026 - acc: 0.944 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 18ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 13/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 3s - loss: 1.1921e-07 - acc: 1.000 - ETA: 2s - loss: 0.6044 - acc: 0.9625    - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 2s - loss: 0.6447 - acc: 0.960 - ETA: 2s - loss: 0.5861 - acc: 0.963 - ETA: 2s - loss: 0.5373 - acc: 0.966 - ETA: 2s - loss: 0.6199 - acc: 0.961 - ETA: 2s - loss: 0.5757 - acc: 0.964 - ETA: 1s - loss: 0.5373 - acc: 0.966 - ETA: 1s - loss: 0.5037 - acc: 0.968 - ETA: 1s - loss: 0.4741 - acc: 0.970 - ETA: 1s - loss: 0.5373 - acc: 0.966 - ETA: 1s - loss: 0.5090 - acc: 0.968 - ETA: 1s - loss: 0.6447 - acc: 0.960 - ETA: 0s - loss: 0.6140 - acc: 0.961 - ETA: 0s - loss: 0.7326 - acc: 0.954 - ETA: 0s - loss: 0.7709 - acc: 0.952 - ETA: 0s - loss: 0.8731 - acc: 0.945 - ETA: 0s - loss: 0.9671 - acc: 0.940 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 4s 17ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - ETA: 3s - loss: 1.6118 - acc: 0.900 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.5373 - acc: 0.966 - ETA: 3s - loss: 1.2089 - acc: 0.925 - ETA: 3s - loss: 0.9671 - acc: 0.940 - ETA: 3s - loss: 1.0745 - acc: 0.933 - ETA: 3s - loss: 1.1513 - acc: 0.928 - ETA: 3s - loss: 1.0074 - acc: 0.937 - ETA: 2s - loss: 0.8954 - acc: 0.944 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7326 - acc: 0.954 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7439 - acc: 0.953 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 1s - loss: 0.9671 - acc: 0.940 - ETA: 1s - loss: 0.9066 - acc: 0.943 - ETA: 1s - loss: 0.8533 - acc: 0.947 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 1s - loss: 0.8483 - acc: 0.947 - ETA: 1s - loss: 0.9671 - acc: 0.940 - ETA: 0s - loss: 0.9210 - acc: 0.942 - ETA: 0s - loss: 0.8792 - acc: 0.945 - ETA: 0s - loss: 0.8409 - acc: 0.947 - ETA: 0s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.8381 - acc: 0.948 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 17ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 15/50\n",
      "265/265 [==============================] - ETA: 3s - loss: 1.6118 - acc: 0.900 - ETA: 3s - loss: 1.6118 - acc: 0.900 - ETA: 3s - loss: 1.6118 - acc: 0.900 - ETA: 3s - loss: 1.2089 - acc: 0.925 - ETA: 3s - loss: 0.9671 - acc: 0.940 - ETA: 3s - loss: 1.0745 - acc: 0.933 - ETA: 3s - loss: 0.9210 - acc: 0.942 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.8954 - acc: 0.944 - ETA: 2s - loss: 0.9671 - acc: 0.940 - ETA: 2s - loss: 0.8792 - acc: 0.945 - ETA: 2s - loss: 0.9402 - acc: 0.941 - ETA: 2s - loss: 0.8679 - acc: 0.946 - ETA: 2s - loss: 0.9210 - acc: 0.942 - ETA: 1s - loss: 0.8596 - acc: 0.946 - ETA: 1s - loss: 0.9066 - acc: 0.943 - ETA: 1s - loss: 0.8533 - acc: 0.947 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 1s - loss: 0.7635 - acc: 0.952 - ETA: 1s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.7675 - acc: 0.952 - ETA: 0s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.8409 - acc: 0.947 - ETA: 0s - loss: 0.8059 - acc: 0.950 - ETA: 0s - loss: 0.9026 - acc: 0.944 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 18ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 16/50\n",
      "265/265 [==============================] - ETA: 4s - loss: 1.1921e-07 - acc: 1.000 - ETA: 4s - loss: 2.0862e-06 - acc: 1.000 - ETA: 4s - loss: 0.5373 - acc: 0.9667    - ETA: 3s - loss: 0.4030 - acc: 0.975 - ETA: 3s - loss: 0.6447 - acc: 0.960 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.9210 - acc: 0.942 - ETA: 3s - loss: 0.8059 - acc: 0.950 - ETA: 3s - loss: 0.8955 - acc: 0.944 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 1.0257 - acc: 0.936 - ETA: 2s - loss: 1.0745 - acc: 0.933 - ETA: 2s - loss: 1.4878 - acc: 0.907 - ETA: 2s - loss: 1.3816 - acc: 0.914 - ETA: 2s - loss: 1.3969 - acc: 0.913 - ETA: 1s - loss: 1.3096 - acc: 0.918 - ETA: 1s - loss: 1.3274 - acc: 0.917 - ETA: 1s - loss: 1.2536 - acc: 0.922 - ETA: 1s - loss: 1.1876 - acc: 0.926 - ETA: 1s - loss: 1.1283 - acc: 0.930 - ETA: 0s - loss: 1.0745 - acc: 0.933 - ETA: 0s - loss: 1.0990 - acc: 0.931 - ETA: 0s - loss: 1.0512 - acc: 0.934 - ETA: 0s - loss: 1.0074 - acc: 0.937 - ETA: 0s - loss: 0.9671 - acc: 0.940 - ETA: 0s - loss: 0.9299 - acc: 0.942 - 5s 18ms/step - loss: 0.9123 - acc: 0.9434\n",
      "Epoch 17/50\n",
      "140/265 [==============>...............] - ETA: 4s - loss: 3.2236 - acc: 0.800 - ETA: 4s - loss: 1.6118 - acc: 0.900 - ETA: 4s - loss: 1.0745 - acc: 0.933 - ETA: 3s - loss: 1.2089 - acc: 0.925 - ETA: 3s - loss: 1.2894 - acc: 0.920 - ETA: 3s - loss: 1.3432 - acc: 0.916 - ETA: 3s - loss: 1.1513 - acc: 0.928 - ETA: 3s - loss: 1.0074 - acc: 0.937 - ETA: 3s - loss: 0.8954 - acc: 0.944 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7326 - acc: 0.954 - ETA: 2s - loss: 0.8059 - acc: 0.950 - ETA: 2s - loss: 0.7439 - acc: 0.953 - ETA: 2s - loss: 0.6908 - acc: 0.9571"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=[w,h,1]))\n",
    "model.add(Conv2D(filters=32, kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5,padding='same'))\n",
    "\n",
    "model.add(Conv2D(filters=50,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5,padding='same'))\n",
    "\n",
    "model.add(Conv2D(filters=80,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=5,padding='same'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x=tr_img_data,y=tr_lbl_data,epochs=50,batch_size=10)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_img = train_data[135][0]\n",
    "    predict_data = test_img.reshape(-1,w,h,1)\n",
    "    model_out = model.predict([predict_data])\n",
    "    print(model_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =plt.figure(figsize=(14,14))\n",
    "plot_cols = 5\n",
    "plot_rows = len(train_data)/plot_cols\n",
    "for cnt, data in enumerate(train_data[:]):\n",
    "    y = fig.add_subplot(plot_rows,plot_cols, cnt+1)\n",
    "    img = data[0]\n",
    "    data = img.reshape(1,w,h,1)\n",
    "    model_out = model.predict([data])\n",
    "    \n",
    "    if np.argmax(model_out) == 1:\n",
    "        str_label = 'No Lights'\n",
    "    else:\n",
    "        str_label = 'Lights'\n",
    "        \n",
    "    y.imshow(img, cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
